# Corrective RAG Engine - 100% Accurate Legal Compliance System
# Implements hallucination detection, hybrid search, and strict citations

import os
import pickle
import faiss
from typing import List, Dict, Any
from sentence_transformers import SentenceTransformer
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_community.retrievers import BM25Retriever
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# --- CONFIGURATION ---
DB_FAISS_PATH = "./vectorstore/db_faiss"

# 1. THE "LEGAL" SYSTEM PROMPT (The Foundation)
LEGAL_SYSTEM_PROMPT = """You are a specialized Legal Research Assistant. Your duty is to answer questions ONLY based on the provided context.

### STRICT RULES:
1. **No Outside Knowledge:** Do not use your internal training data to answer. If the answer is not in the context, say "I do not have enough information in the provided documents."
2. **Citation Requirement:** Every single claim must be backed by a specific source ID (e.g., [Source: 1]).
3. **Uncertainty:** If a law or rule is ambiguous in the text, state the ambiguity clearly. Do not guess.
4. **Tone:** Professional, objective, and precise.

### FORMAT:
- Answer: [Your answer here]
- Sources: [List of Source IDs used]"""

# 2. DATA MODELS FOR STRUCTURED OUTPUT
class Citation(BaseModel):
    """Single citation with source ID and exact quote."""
    source_id: int = Field(..., description="The integer ID of a SPECIFIC source document")
    quote: str = Field(..., description="The exact quote from the document justifying the claim")

class CitedAnswer(BaseModel):
    """Answer the user question based only on the given sources, and cite the sources used."""
    answer: str = Field(..., description="The answer to the user question")
    citations: list[Citation] = Field(..., description="Citations from the given sources")

class GradeHallucinations(BaseModel):
    """Binary score for hallucination present in generation answer."""
    binary_score: str = Field(description="Answer is grounded in the facts, 'yes' or 'no'")

# 3. HYBRID SEARCH RETRIEVER
def get_hybrid_retriever(documents: List[Document]):
    """
    Implements Hybrid Search combining keyword (BM25) and semantic (FAISS) retrieval
    """
    try:
        # 1. Keyword Retriever (Finds exact words like "Section 23")
        bm25_retriever = BM25Retriever.from_documents(documents)
        bm25_retriever.k = 3

        # 2. Semantic Retriever (Finds meaning like "punishment for fraud")
        # Use sentence transformers for consistency with existing setup
        vectorstore = FAISS.from_documents(documents, OpenAIEmbeddings())
        faiss_retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

        # 3. Simple hybrid: combine results from both
        class HybridRetriever:
            def __init__(self, bm25, faiss):
                self.bm25 = bm25
                self.faiss = faiss
            
            def invoke(self, query):
                bm25_docs = self.bm25.invoke(query)
                faiss_docs = self.faiss.invoke(query)
                
                # Combine and deduplicate
                all_docs = bm25_docs + faiss_docs
                seen_content = set()
                unique_docs = []
                
                for doc in all_docs:
                    content_hash = hash(doc.page_content[:200])
                    if content_hash not in seen_content:
                        seen_content.add(content_hash)
                        unique_docs.append(doc)
                        if len(unique_docs) >= 5:
                            break
                
                return unique_docs
        
        return HybridRetriever(bm25_retriever, faiss_retriever)
        
    except Exception as e:
        print(f"Error creating hybrid retriever: {e}")
        # Fallback to simple FAISS retriever
        vectorstore = FAISS.from_documents(documents, OpenAIEmbeddings())
        return vectorstore.as_retriever(search_kwargs={"k": 5})

# 4. HALLUCINATION GRADER (The Verifier)
class HallucinationGrader:
    """Grades whether the LLM answer is supported by the retrieved documents"""
    
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        self.structured_llm_grader = self.llm.with_structured_output(GradeHallucinations)
        
        # The Grader Prompt
        system = """You are a grader assessing an AI generation. 
        Your task is to check if the LLM's answer is supported by the retrieved FACTS.
        Give a binary score 'yes' or 'no'. 'yes' means the answer is fully grounded in the facts."""
        
        self.grader_prompt = ChatPromptTemplate.from_messages([
            ("system", system),
            ("human", "FACTS: \n\n {documents} \n\n LLM ANSWER: {generation}"),
        ])
        
        self.hallucination_grader = self.grader_prompt | self.structured_llm_grader
    
    def verify_answer(self, context: str, answer: str) -> bool:
        """
        Verifies if the answer is supported by the context
        Returns True if answer is grounded, False if hallucination detected
        """
        try:
            score = self.hallucination_grader.invoke({
                "documents": context, 
                "generation": answer
            })
            return score.binary_score == "yes"
        except Exception as e:
            print(f"Error in hallucination grading: {e}")
            return False  # Err on side of caution

# 5. MAIN CORRECTIVE RAG ENGINE
class CorrectiveRAGEngine:
    """Main engine that combines hybrid search, structured output, and hallucination detection"""
    
    def __init__(self):
        self.hallucination_grader = HallucinationGrader()
        self.documents = []
        self.retriever = None
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        self.citation_llm = self.llm.with_structured_output(CitedAnswer)
        
        # Load and setup documents
        self._load_documents()
        self._setup_retriever()
    
    def _load_documents(self):
        """Load documents from FAISS index"""
        try:
            # Load the FAISS index created with sentence transformers
            index = faiss.read_index(os.path.join(DB_FAISS_PATH, "index.faiss"))
            
            # Load chunks metadata
            with open(os.path.join(DB_FAISS_PATH, "chunks.pkl"), 'rb') as f:
                chunks = pickle.load(f)
            
            # Convert to Document objects
            self.documents = []
            for i, chunk in enumerate(chunks):
                doc = Document(
                    page_content=chunk.page_content,
                    metadata={"source": f"Document_{i+1}", **chunk.metadata}
                )
                self.documents.append(doc)
                
        except Exception as e:
            print(f"Error loading documents: {e}")
            self.documents = []
    
    def _setup_retriever(self):
        """Setup the hybrid retriever"""
        if self.documents:
            self.retriever = get_hybrid_retriever(self.documents)
        else:
            self.retriever = None
    
    def _generate_cited_answer(self, question: str, context_docs: List[Document]) -> CitedAnswer:
        """Generate answer with inline citations"""
        # Prepare context with source IDs
        context_text = ""
        for i, doc in enumerate(context_docs):
            context_text += f"[Source {i+1}]: {doc.page_content}\n\n"
        
        # Create prompt with legal system instructions
        prompt = f"""{LEGAL_SYSTEM_PROMPT}

CONTEXT:
{context_text}

QUESTION: {question}

Answer the question based ONLY on the provided context. Include specific source citations."""
        
        try:
            # Generate structured answer with citations
            result = self.citation_llm.invoke(prompt)
            return result
        except Exception as e:
            print(f"Error generating cited answer: {e}")
            # Fallback
            return CitedAnswer(
                answer="I encountered an error generating the answer.",
                citations=[]
            )
    
    def get_verified_answer(self, question: str) -> Dict[str, Any]:
        """
        Main method to get verified answer with hallucination detection
        """
        if not self.retriever:
            return {
                "answer": "Error: Knowledge base not available. Please ensure documents are properly ingested.",
                "citations": [],
                "verified": False,
                "sources": []
            }
        
        try:
            # Step 1: Retrieve relevant documents using hybrid search
            retrieved_docs = self.retriever.invoke(question)
            
            if not retrieved_docs:
                return {
                    "answer": "I do not have enough information in the provided documents to answer this question.",
                    "citations": [],
                    "verified": False,
                    "sources": []
                }
            
            # Step 2: Generate answer with citations
            cited_answer = self._generate_cited_answer(question, retrieved_docs)
            
            # Step 3: Verify answer for hallucinations
            context_text = "\n\n".join([doc.page_content for doc in retrieved_docs])
            is_verified = self.hallucination_grader.verify_answer(context_text, cited_answer.answer)
            
            # Step 4: Return result
            return {
                "answer": cited_answer.answer,
                "citations": [{"source_id": c.source_id, "quote": c.quote} for c in cited_answer.citations],
                "verified": is_verified,
                "sources": [doc.metadata.get("source", f"Document_{i+1}") for i, doc in enumerate(retrieved_docs)]
            }
            
        except Exception as e:
            return {
                "answer": f"Error processing question: {str(e)}",
                "citations": [],
                "verified": False,
                "sources": []
            }

# 6. MAIN FUNCTION FOR STREAMLIT INTEGRATION
def get_corrective_rag_answer(question: str) -> Dict[str, Any]:
    """
    Main function to call from Streamlit app
    Returns verified answer with citations
    """
    engine = CorrectiveRAGEngine()
    return engine.get_verified_answer(question)

if __name__ == "__main__":
    # Test the Corrective RAG Engine
    test_questions = [
        "What is the punishment for fraud under Section 447?",
        "What is the collateral free loan limit for MSEs?",
        "Does my LLP need to get accounts audited if turnover is â‚¹35 Lakhs?"
    ]
    
    print("ğŸ” Corrective RAG Engine Test")
    print("=" * 60)
    
    for i, question in enumerate(test_questions, 1):
        print(f"\nğŸ“ Test {i}: {question}")
        print("-" * 40)
        
        result = get_corrective_rag_answer(question)
        
        print(f"Answer: {result['answer']}")
        print(f"Verified: {'âœ… YES' if result['verified'] else 'âŒ NO'}")
        print(f"Citations: {len(result['citations'])}")
        for citation in result['citations']:
            print(f"  - Source {citation['source_id']}: {citation['quote'][:100]}...")
        print("=" * 60)
